{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "seeing-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from quantities.units.area import D\n",
    "import pandas as pd\n",
    "import sklearn_crfsuite\n",
    "import spacy\n",
    "import quantities\n",
    "from quantities import units\n",
    "from quantities.unitquantity import UnitQuantity as UQ\n",
    "from sklearn_crfsuite import metrics\n",
    "from pprint import pprint\n",
    "\n",
    "import scipy\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "utility-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "potential-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {'QUANT' : 'Quantity'}\n",
    "lang_model = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "activated-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_list = []\n",
    "\n",
    "train_raw_files = glob.glob(\"train/text/*.txt\")\n",
    "train_tsv_files = glob.glob(\"train/tsv/*.tsv\")\n",
    "test_raw_files = glob.glob(\"trial/txt/*.txt\")\n",
    "test_tsv_files = glob.glob(\"trial/tsv/*.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "irish-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_text_to_df(raw_files):\n",
    "    \"\"\"converting raw training files to dataframes\"\"\"\n",
    "    # dict to be exported as dataframe\n",
    "    documents_of_interest = {\n",
    "        'document_name': [],\n",
    "        'sentence': [],\n",
    "        'entities': [],\n",
    "        'np': []\n",
    "    }\n",
    "    # filling the dict\n",
    "    for raw_file in raw_files:\n",
    "        with open(raw_file, \"r\") as file:\n",
    "            # print(file.name.split('/')[2])\n",
    "            doc_name = file.name.split(\"/\")[2]\n",
    "            doc_name = doc_name.split('.')[0]\n",
    "            file_content = lang_model(file.read())\n",
    "            for sentence in file_content.sents:\n",
    "                sentence_pos_tags = [word.tag_ for word in sentence]\n",
    "#                 if \"CD\" in sentence_pos_tags:\n",
    "                documents_of_interest['document_name'].append(doc_name)\n",
    "                documents_of_interest['sentence'].append(sentence)\n",
    "                entities = []\n",
    "                for measurement in sentence.ents:\n",
    "                    entities.append((measurement.label_,(measurement.start, measurement.end)))\n",
    "                documents_of_interest['entities'].append(\n",
    "                    entities\n",
    "                )\n",
    "\n",
    "                noun_phrases = []\n",
    "\n",
    "                for chunk in sentence.noun_chunks:\n",
    "                    noun_phrases.append((chunk.text, (chunk.start, chunk.end)))\n",
    "                documents_of_interest['np'].append(noun_phrases)\n",
    "                    \n",
    "        # break\n",
    "    dataframe = pd.DataFrame(\n",
    "        documents_of_interest,\n",
    "        columns=['document_name', 'sentence', 'entities', 'np'],\n",
    "    )\n",
    "    # pprint(dataframe)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cutting-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_labels(text_dataframe, tsv_dataframe):\n",
    "    labels = []\n",
    "    for _, text_row in text_dataframe.iterrows():\n",
    "        sentence_tag_placeholders = []\n",
    "        for word in text_row['sentence']:\n",
    "            sentence_tag_placeholders.append(\n",
    "                ['O', (word.idx, (word.idx + len(word)))]\n",
    "            )\n",
    "        # O means not a quantity QUANT means quantity\n",
    "        document_name = text_row['document_name']\n",
    "        print(document_name)\n",
    "        doc_id = tsv_dataframe['docId'] == document_name\n",
    "        for _, annot_row in tsv_dataframe[doc_id].iterrows():\n",
    "            annotType = annot_row['annotType']\n",
    "            if annotType == 'Qualifier':\n",
    "                continue\n",
    "            \n",
    "            if annotType == 'Quantity':\n",
    "                annotType = 'QUANT'\n",
    "            else :\n",
    "                annotType = 'O'\n",
    "\n",
    "            for i, item in enumerate(sentence_tag_placeholders):\n",
    "                if item[0] != 'O':\n",
    "                    continue\n",
    "                \n",
    "                if (annot_row['startOffset'] <= item[1][0] < annot_row['endOffset']) or (annot_row['startOffset'] < item[1][1] <= annot_row['endOffset']):\n",
    "                    if annotType != 'O':\n",
    "                        sentence_tag_placeholders[i][0] = annotType\n",
    "        \n",
    "\n",
    "        labels.append([label for label, _ in sentence_tag_placeholders])\n",
    "                \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "active-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_units() :\n",
    "    units_list = ['%'] # Add possible unit symbols\n",
    "    for key, value in units.__dict__.items():\n",
    "        if isinstance(value, UQ):\n",
    "            if key not in units_list :\n",
    "                units_list.append(key.lower())\n",
    "            if value.name not in units_list :\n",
    "                units_list.append(value.name.lower())\n",
    "        \n",
    "    return units_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "reported-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_unit(token):\n",
    "    return token.lower_ in units_list or token.lemma_ in units_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "popular-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_word(word, entities, nouns, length, pos):\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'lower': word.lower_,\n",
    "        'lemma': word.lemma_,\n",
    "        'upper': word.is_upper,\n",
    "        'title': word.is_title,\n",
    "        'digit': word.is_digit,\n",
    "        'numlike': word.like_num,\n",
    "        'unit': is_unit(word),\n",
    "        'postag': word.tag_,\n",
    "        'dep': word.dep_\n",
    "    }\n",
    "    \n",
    "    for entity in entities:\n",
    "        if entity[1][0] <= word.i < entity[1][1]:\n",
    "            features['entity'] = entity[0]\n",
    "            break\n",
    "    \n",
    "    for noun in nouns:\n",
    "        if noun[1][0] <= word.i < noun[1][1]:\n",
    "            features['np'] = list(noun[0])\n",
    "            break\n",
    "    \n",
    "    if pos >= 1 :\n",
    "        new_word = word.nbor(-1)\n",
    "        features.update({\n",
    "            '-1:lower': new_word.lower_,\n",
    "            '-1:lemma': new_word.lemma_,\n",
    "            '-1:upper': new_word.is_upper,\n",
    "            '-1:title': new_word.is_title,\n",
    "            '-1:digit': new_word.is_digit,\n",
    "            '-1:numlike': new_word.like_num,\n",
    "            '-1:unit': is_unit(new_word),\n",
    "            '-1:postag': new_word.tag_,\n",
    "            '-1:dep': new_word.dep_\n",
    "        })\n",
    "        \n",
    "        \n",
    "    if pos <= length-2 :\n",
    "        new_word = word.nbor(1)\n",
    "        features.update({\n",
    "            '+1:lower': new_word.lower_,\n",
    "            '+1:lemma': new_word.lemma_,\n",
    "            '+:upper': new_word.is_upper,\n",
    "            '+:title': new_word.is_title,\n",
    "            '+:digit': new_word.is_digit,\n",
    "            '+:numlike': new_word.like_num,\n",
    "            '+:unit': is_unit(new_word),\n",
    "            '+:postag': new_word.tag_,\n",
    "            '+:dep': new_word.dep_\n",
    "        })\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "sudden-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_sentence(sentence, entities, nouns):\n",
    "    sentence_features = []\n",
    "    for i in range(0, len(sentence)) :\n",
    "        word_features = features_word(sentence[i], entities, nouns, len(sentence), i)\n",
    "        sentence_features.append(word_features)\n",
    "    return sentence_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "purple-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_list = get_units()\n",
    "\n",
    "train_text_dataframe = raw_text_to_df(train_raw_files)\n",
    "train_text_dataframe.to_csv(\"./CSV/train_text_dataframe.csv\")\n",
    "\n",
    "each_file_df = []\n",
    "for tsv_file in train_tsv_files:\n",
    "    each_file_df.append(pd.read_csv(tsv_file, sep=\"\\t\", header=0))\n",
    "\n",
    "train_tsv_dataframe = pd.concat(each_file_df)\n",
    "train_tsv_dataframe.to_csv(\"./CSV/train_tsv_dataframe.csv\")\n",
    "\n",
    "test_text_dataframe = raw_text_to_df(test_raw_files)\n",
    "test_text_dataframe.to_csv(\"./CSV/test_text_dataframe.csv\")\n",
    "\n",
    "each_file_test = []\n",
    "for tsv_file in test_tsv_files:\n",
    "    each_file_test.append(pd.read_csv(tsv_file, sep=\"\\t\", header=0))\n",
    "\n",
    "test_tsv_dataframe = pd.concat(each_file_test)\n",
    "test_tsv_dataframe.to_csv(\"./CSV/test_tsv_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fewer-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for _, row in train_text_dataframe.iterrows() :\n",
    "    features = features_sentence(row['sentence'], row['entities'], row['np'])\n",
    "    X_train.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "designing-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_text_labels(train_text_dataframe, train_tsv_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "leading-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for _, row in test_text_dataframe.iterrows() :\n",
    "    features = features_sentence(row['sentence'], row['entities'], row['np'])\n",
    "    X_test.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "british-collar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              document_name  \\\n",
      "0    S0019103512004009-4007   \n",
      "1    S0019103512004009-4007   \n",
      "2    S0019103512004009-4007   \n",
      "3    S0019103512004009-4007   \n",
      "4    S0019103512004009-4007   \n",
      "..                      ...   \n",
      "506  S0019103512003533-3299   \n",
      "507  S0019103512003533-3299   \n",
      "508  S0019103512003533-3299   \n",
      "509  S0019103512003533-3299   \n",
      "510  S0019103512003533-3299   \n",
      "\n",
      "                                              sentence  \\\n",
      "0    (In, the, previous, section, we, discussed, mo...   \n",
      "1    (In, this, section, we, discuss, more, realist...   \n",
      "2    (Here, we, also, include, radiative, cooling, ...   \n",
      "3    (Our, aim, was, to, calculate, the, most, like...   \n",
      "4                                             (Fig, .)   \n",
      "..                                                 ...   \n",
      "506  (Solar, EUV, heating, is, calculated, through,...   \n",
      "507                                    ((, 1983, ), .)   \n",
      "508  (While, we, include, direct, solar, EUV, heati...   \n",
      "509                                    ((, 2006, ), .)   \n",
      "510  (We, show, in, Section, 3, that, the, main, im...   \n",
      "\n",
      "                                              entities  \\\n",
      "0                                                   []   \n",
      "1                                                   []   \n",
      "2             [(CARDINAL, (64, 65)), (DATE, (82, 83))]   \n",
      "3                                                   []   \n",
      "4                               [(PERSON, (107, 108))]   \n",
      "..                                                 ...   \n",
      "506  [(FAC, (166, 177)), (DATE, (186, 187)), (PERCE...   \n",
      "507                               [(DATE, (213, 214))]   \n",
      "508      [(PRODUCT, (237, 238)), (PERSON, (245, 248))]   \n",
      "509                               [(DATE, (252, 253))]   \n",
      "510          [(LAW, (258, 260)), (PERSON, (278, 279))]   \n",
      "\n",
      "                                                    np  \n",
      "0    [(the previous section, (1, 4)), (we, (4, 5)),...  \n",
      "1    [(this section, (24, 26)), (we, (26, 27)), (mo...  \n",
      "2    [(we, (54, 55)), (radiative cooling, (57, 59))...  \n",
      "3    [(Our aim, (85, 87)), (the most likely range, ...  \n",
      "4                                  [(Fig, (107, 108))]  \n",
      "..                                                 ...  \n",
      "506  [(Solar EUV heating, (136, 139)), (sight, (147...  \n",
      "507                                                 []  \n",
      "508  [(we, (217, 218)), (direct solar EUV heating, ...  \n",
      "509                                                 []  \n",
      "510  [(We, (255, 256)), (Section, (258, 259)), (the...  \n",
      "\n",
      "[511 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_text_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "rough-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = get_text_labels(test_text_dataframe, test_tsv_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "handled-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "nasty-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_to_tsv(text_dataframe, y_pred):\n",
    "    tsv_columns = [\n",
    "        \"docId\",\n",
    "        \"annotSet\",\n",
    "        \"annotType\",\n",
    "        \"startOffset\",\n",
    "        \"endOffset\",\n",
    "        \"annotId\",\n",
    "        \"text\",\n",
    "        \"other\"\n",
    "    ]\n",
    "    # save the results in appropriate format in a new dataframe\n",
    "    row_id = 0\n",
    "    output_list = []\n",
    "    prev_file = \"\"\n",
    "    annot_set_index = 1\n",
    "    annot_index = 1\n",
    "    for i, text_row in text_dataframe.iterrows():\n",
    "        file_name = text_row['document_name']\n",
    "        if i > 0 and file_name != prev_file:\n",
    "            result_df = pd.DataFrame(output_list, columns=tsv_columns)\n",
    "            result_df.to_csv('results/' + prev_file + '.tsv', sep=\"\\t\", index=False)\n",
    "            output_list = []\n",
    "            annot_set_index = 1\n",
    "            annot_index = 1\n",
    "\n",
    "        pred_pos = y_pred[row_id]\n",
    "        row_id += 1\n",
    "        sentence = text_row['sentence']\n",
    "        word_ind = 0\n",
    "#         for word in text_row['sentence']:\n",
    "#             word_ind += 1\n",
    "#             if word.tag_ != \"CD\" or pred_pos[word_ind] != \"QUANT\":\n",
    "#                 continue\n",
    "#             if word_ind >= len(pred_pos) - 1 or pred_pos[word_ind + 1] != \"QUANT\":\n",
    "#                 result_df.append([file_name, annot_set_index, tags['QUANT'], word.i, word.i + len(word) - 1])\n",
    "            \n",
    "#         file_path = 'results/'+str(file_name)+'.tsv'\n",
    "#         with open(file_path, 'w') as file:\n",
    "#             result_df.append(\n",
    "                \n",
    "#             )\n",
    "        while word_ind < len(pred_pos) :\n",
    "            if pred_pos[word_ind] == 'O':\n",
    "                word_ind += 1\n",
    "                continue\n",
    "            \n",
    "            start_ind = word_ind\n",
    "            while word_ind < len(pred_pos) and pred_pos[word_ind] == 'QUANT':\n",
    "                word_ind += 1\n",
    "            end_ind = word_ind - 1\n",
    "            \n",
    "#             quant_text = \"\"\n",
    "#             for x in range(start_ind, end_ind + 1):\n",
    "#                 quant_text += sentence[x].text\n",
    "#                 if x != end_ind : \n",
    "#                     quant_text += \" \"\n",
    "            quant_text = sentence.doc[sentence[start_ind].i : sentence[end_ind].i + 1]\n",
    "#             result_df.append([file_name, annot_set_index, tags['QUANT'], sentence[start_ind].i, sentence[end_ind].i + len(sentence[end_ind]), annot_index, quant_text, \"\"])\n",
    "#             result_df.append({\n",
    "#                 'docId' : file_name,\n",
    "#                 'annotSet' : annot_set_index,\n",
    "#                 'annotType' : tags['QUANT'],\n",
    "#                 'startOffset' : sentence[start_ind].i,\n",
    "#                 'endOffset' : sentence[end_ind].i + len(sentence[end_ind]),\n",
    "#                 'annotId' : annot_index,\n",
    "#                 'text' : quant_text,\n",
    "#                 'other' : \"Empty\"\n",
    "#             }, ignore_index=True)\n",
    "            \n",
    "            output_list.append([file_name, annot_set_index, tags['QUANT'], sentence[start_ind].idx, sentence[end_ind].idx + len(sentence[end_ind]), annot_index, quant_text, \"\"])\n",
    "            annot_set_index += 1\n",
    "            annot_index += 1\n",
    "        \n",
    "        prev_file = file_name\n",
    "        \n",
    "    result_df = pd.DataFrame(output_list, columns=tsv_columns)\n",
    "    result_df.to_csv('results/' + prev_file + '.tsv', sep=\"\\t\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dressed-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_to_tsv(test_text_dataframe, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "affecting-revision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotSet</th>\n",
       "      <th>annotType</th>\n",
       "      <th>startOffset</th>\n",
       "      <th>endOffset</th>\n",
       "      <th>annotId</th>\n",
       "      <th>text</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0019103512004009-4007</td>\n",
       "      <td>1</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>776</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "      <td>93%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0019103512004009-4007</td>\n",
       "      <td>2</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>894</td>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>50 eV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0019103512004009-4007</td>\n",
       "      <td>3</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>944</td>\n",
       "      <td>947</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    docId  annotSet annotType  startOffset  endOffset  \\\n",
       "0  S0019103512004009-4007         1  Quantity          776        779   \n",
       "1  S0019103512004009-4007         2  Quantity          894        899   \n",
       "2  S0019103512004009-4007         3  Quantity          944        947   \n",
       "\n",
       "   annotId   text  other  \n",
       "0        1    93%    NaN  \n",
       "1        2  50 eV    NaN  \n",
       "2        3    0.1    NaN  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"results/S0019103512004009-4007.tsv\",sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "running-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    " for i, text_row in test_text_dataframe.iterrows():\n",
    "        print(type(text_row['sentence'][3].doc))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "accompanied-fabric",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CRF' object has no attribute 'keep_tempfiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;34m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"text/plain\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"display\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'diagram'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text/html\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_params\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnested_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msub_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0;32m--> 393\u001b[0;31m                                                 self._depth, level)\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_changed_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             krepr, kreadable, krecur = saferepr(\n\u001b[0m\u001b[1;32m    426\u001b[0m                 k, context, maxlevels, level, changed_only=changed_only)\n\u001b[1;32m    427\u001b[0m             vrepr, vreadable, vrecur = saferepr(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     89\u001b[0m     estimator with non-default values.\"\"\"\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mfiltered_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     init_func = getattr(estimator.__init__, 'deprecated_original',\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mdeep\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwill\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mcontained\u001b[0m \u001b[0msubobjects\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mare\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CRF' object has no attribute 'keep_tempfiles'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CRF' object has no attribute 'keep_tempfiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_params\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnested_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msub_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0;32m--> 393\u001b[0;31m                                                 self._depth, level)\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_changed_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             krepr, kreadable, krecur = saferepr(\n\u001b[0m\u001b[1;32m    426\u001b[0m                 k, context, maxlevels, level, changed_only=changed_only)\n\u001b[1;32m    427\u001b[0m             vrepr, vreadable, vrecur = saferepr(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     89\u001b[0m     estimator with non-default values.\"\"\"\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mfiltered_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     init_func = getattr(estimator.__init__, 'deprecated_original',\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mdeep\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwill\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mcontained\u001b[0m \u001b[0msubobjects\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mare\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CRF' object has no attribute 'keep_tempfiles'"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "reliable-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "invisible-corpus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=['QUANT'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  return f(**kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  average_options = (None, 'micro', 'macro', 'weighted', 'samples')\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  average_options = (None, 'micro', 'macro', 'weighted', 'samples')\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  average_options = (None, 'micro', 'macro', 'weighted', 'samples')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       QUANT      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.000     0.000     0.000         0\n",
      "   macro avg      0.000     0.000     0.000         0\n",
      "weighted avg      0.000     0.000     0.000         0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  average_options = (None, 'micro', 'macro', 'weighted', 'samples')\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "certified-coverage",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-cf90604f5d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m f1_scorer = make_scorer(metrics.flat_f1_score,\n\u001b[0;32m---> 15\u001b[0;31m                         average='weighted', labels=labels)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m rs = RandomizedSearchCV(crf, params_space,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05), \n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "nervous-classroom",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-5971df7dd589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m print(metrics.flat_classification_report(\n\u001b[1;32m      4\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rs' is not defined"
     ]
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
