{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "backed-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from quantities.units.area import D\n",
    "import pandas as pd\n",
    "import sklearn_crfsuite\n",
    "import spacy\n",
    "import quantities\n",
    "from quantities import units\n",
    "from quantities.unitquantity import UnitQuantity as UQ\n",
    "from sklearn_crfsuite import metrics\n",
    "from pprint import pprint\n",
    "\n",
    "import scipy\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expired-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "significant-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {'QUANT' : 'Quantity'}\n",
    "lang_model = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "natural-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_list = []\n",
    "\n",
    "train_raw_files = glob.glob(\"train/text/*.txt\")\n",
    "train_tsv_files = glob.glob(\"train/tsv/*.tsv\")\n",
    "test_raw_files = glob.glob(\"trial/txt/*.txt\")\n",
    "test_tsv_files = glob.glob(\"trial/tsv/*.tsv\")\n",
    "eval_raw_files = glob.glob(\"eval/text/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recognized-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_text_to_df(raw_files):\n",
    "    \"\"\"converting raw training files to dataframes\"\"\"\n",
    "    # dict to be exported as dataframe\n",
    "    documents_of_interest = {\n",
    "        'document_name': [],\n",
    "        'sentence': [],\n",
    "        'entities': [],\n",
    "        'np': []\n",
    "    }\n",
    "    # filling the dict\n",
    "    for raw_file in raw_files:\n",
    "        with open(raw_file, \"r\") as file:\n",
    "            # print(file.name.split('/')[2])\n",
    "            doc_name = file.name.split(\"/\")[2]\n",
    "            doc_name = doc_name.split('.')[0]\n",
    "            file_content = lang_model(file.read())\n",
    "            for sentence in file_content.sents:\n",
    "                sentence_pos_tags = [word.tag_ for word in sentence]\n",
    "                documents_of_interest['document_name'].append(doc_name)\n",
    "                documents_of_interest['sentence'].append(sentence)\n",
    "                entities = []\n",
    "                for measurement in sentence.ents:\n",
    "                    entities.append((measurement.label_,(measurement.start, measurement.end)))\n",
    "                documents_of_interest['entities'].append(\n",
    "                    entities\n",
    "                )\n",
    "\n",
    "                noun_phrases = []\n",
    "\n",
    "                for chunk in sentence.noun_chunks:\n",
    "                    noun_phrases.append((chunk.text, (chunk.start, chunk.end)))\n",
    "                documents_of_interest['np'].append(noun_phrases)\n",
    "                    \n",
    "        # break\n",
    "    dataframe = pd.DataFrame(\n",
    "        documents_of_interest,\n",
    "        columns=['document_name', 'sentence', 'entities', 'np'],\n",
    "    )\n",
    "    # pprint(dataframe)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "federal-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_labels(text_dataframe, tsv_dataframe):\n",
    "    labels = []\n",
    "    for _, text_row in text_dataframe.iterrows():\n",
    "        sentence_tag_placeholders = []\n",
    "        for word in text_row['sentence']:\n",
    "            sentence_tag_placeholders.append(\n",
    "                ['O', (word.idx, (word.idx + len(word)))]\n",
    "            )\n",
    "        # O means not a quantity QUANT means quantity\n",
    "        document_name = text_row['document_name']\n",
    "#         print(document_name)\n",
    "        doc_id = tsv_dataframe['docId'] == document_name\n",
    "        for _, annot_row in tsv_dataframe[doc_id].iterrows():\n",
    "            annotType = annot_row['annotType']\n",
    "            if annotType == 'Qualifier':\n",
    "                continue\n",
    "            \n",
    "            if annotType == 'Quantity':\n",
    "                annotType = 'QUANT'\n",
    "            else :\n",
    "                annotType = 'O'\n",
    "\n",
    "            for i, item in enumerate(sentence_tag_placeholders):\n",
    "                if item[0] != 'O':\n",
    "                    continue\n",
    "                \n",
    "                if (annot_row['startOffset'] <= item[1][0] < annot_row['endOffset']) or (annot_row['startOffset'] < item[1][1] <= annot_row['endOffset']):\n",
    "                    if annotType != 'O':\n",
    "                        sentence_tag_placeholders[i][0] = annotType\n",
    "        \n",
    "\n",
    "        labels.append([label for label, _ in sentence_tag_placeholders])\n",
    "                \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_units() :\n",
    "    units_list = ['%'] # Add possible unit symbols\n",
    "    for key, value in units.__dict__.items():\n",
    "        if isinstance(value, UQ):\n",
    "            if key not in units_list :\n",
    "                units_list.append(key.lower())\n",
    "            if value.name not in units_list :\n",
    "                units_list.append(value.name.lower())\n",
    "        \n",
    "    return units_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coordinated-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_unit(token):\n",
    "    return token.lower_ in units_list or token.lemma_ in units_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pharmaceutical-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_word(word, entities, nouns, length, pos):\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'lower': word.lower_,\n",
    "        'lemma': word.lemma_,\n",
    "        'upper': word.is_upper,\n",
    "        'title': word.is_title,\n",
    "        'digit': word.is_digit,\n",
    "        'numlike': word.like_num,\n",
    "        'unit': is_unit(word),\n",
    "        'postag': word.tag_,\n",
    "        'dep': word.dep_\n",
    "    }\n",
    "    \n",
    "    for entity in entities:\n",
    "        if entity[1][0] <= word.i < entity[1][1]:\n",
    "            features['entity'] = entity[0]\n",
    "            break\n",
    "    \n",
    "    for noun in nouns:\n",
    "        if noun[1][0] <= word.i < noun[1][1]:\n",
    "            features['np'] = list(noun[0])\n",
    "            break\n",
    "    \n",
    "    if pos >= 1 :\n",
    "        new_word = word.nbor(-1)\n",
    "        features.update({\n",
    "            '-1:lower': new_word.lower_,\n",
    "            '-1:lemma': new_word.lemma_,\n",
    "            '-1:upper': new_word.is_upper,\n",
    "            '-1:title': new_word.is_title,\n",
    "            '-1:digit': new_word.is_digit,\n",
    "            '-1:numlike': new_word.like_num,\n",
    "            '-1:unit': is_unit(new_word),\n",
    "            '-1:postag': new_word.tag_,\n",
    "            '-1:dep': new_word.dep_\n",
    "        })\n",
    "        \n",
    "        \n",
    "    if pos <= length-2 :\n",
    "        new_word = word.nbor(1)\n",
    "        features.update({\n",
    "            '+1:lower': new_word.lower_,\n",
    "            '+1:lemma': new_word.lemma_,\n",
    "            '+:upper': new_word.is_upper,\n",
    "            '+:title': new_word.is_title,\n",
    "            '+:digit': new_word.is_digit,\n",
    "            '+:numlike': new_word.like_num,\n",
    "            '+:unit': is_unit(new_word),\n",
    "            '+:postag': new_word.tag_,\n",
    "            '+:dep': new_word.dep_\n",
    "        })\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spoken-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_sentence(sentence, entities, nouns):\n",
    "    sentence_features = []\n",
    "    for i in range(0, len(sentence)) :\n",
    "        word_features = features_word(sentence[i], entities, nouns, len(sentence), i)\n",
    "        sentence_features.append(word_features)\n",
    "    return sentence_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "concerned-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_to_tsv(text_dataframe, y_pred, dirname):\n",
    "    tsv_columns = [\n",
    "        \"docId\",\n",
    "        \"annotSet\",\n",
    "        \"annotType\",\n",
    "        \"startOffset\",\n",
    "        \"endOffset\",\n",
    "        \"annotId\",\n",
    "        \"text\",\n",
    "        \"other\"\n",
    "    ]\n",
    "    # save the results in appropriate format in a new dataframe\n",
    "    row_id = 0\n",
    "    output_list = []\n",
    "    prev_file = \"\"\n",
    "    annot_set_index = 1\n",
    "    annot_index = 1\n",
    "    for i, text_row in text_dataframe.iterrows():\n",
    "        file_name = text_row['document_name']\n",
    "        if i > 0 and file_name != prev_file:\n",
    "            result_df = pd.DataFrame(output_list, columns=tsv_columns)\n",
    "            result_df.to_csv(dirname + prev_file + '.tsv', sep=\"\\t\", index=False)\n",
    "            output_list = []\n",
    "            annot_set_index = 1\n",
    "            annot_index = 1\n",
    "\n",
    "        pred_pos = y_pred[row_id]\n",
    "        row_id += 1\n",
    "        sentence = text_row['sentence']\n",
    "        word_ind = 0\n",
    "#         for word in text_row['sentence']:\n",
    "#             word_ind += 1\n",
    "#             if word.tag_ != \"CD\" or pred_pos[word_ind] != \"QUANT\":\n",
    "#                 continue\n",
    "#             if word_ind >= len(pred_pos) - 1 or pred_pos[word_ind + 1] != \"QUANT\":\n",
    "#                 result_df.append([file_name, annot_set_index, tags['QUANT'], word.i, word.i + len(word) - 1])\n",
    "            \n",
    "#         file_path = 'results/'+str(file_name)+'.tsv'\n",
    "#         with open(file_path, 'w') as file:\n",
    "#             result_df.append(\n",
    "                \n",
    "#             )\n",
    "        while word_ind < len(pred_pos) :\n",
    "            if pred_pos[word_ind] == 'O':\n",
    "                word_ind += 1\n",
    "                continue\n",
    "            \n",
    "            start_ind = word_ind\n",
    "            while word_ind < len(pred_pos) and pred_pos[word_ind] == 'QUANT':\n",
    "                word_ind += 1\n",
    "            end_ind = word_ind - 1\n",
    "            \n",
    "#             quant_text = \"\"\n",
    "#             for x in range(start_ind, end_ind + 1):\n",
    "#                 quant_text += sentence[x].text\n",
    "#                 if x != end_ind : \n",
    "#                     quant_text += \" \"\n",
    "            quant_text = sentence.doc[sentence[start_ind].i : sentence[end_ind].i + 1]\n",
    "#             result_df.append([file_name, annot_set_index, tags['QUANT'], sentence[start_ind].i, sentence[end_ind].i + len(sentence[end_ind]), annot_index, quant_text, \"\"])\n",
    "#             result_df.append({\n",
    "#                 'docId' : file_name,\n",
    "#                 'annotSet' : annot_set_index,\n",
    "#                 'annotType' : tags['QUANT'],\n",
    "#                 'startOffset' : sentence[start_ind].i,\n",
    "#                 'endOffset' : sentence[end_ind].i + len(sentence[end_ind]),\n",
    "#                 'annotId' : annot_index,\n",
    "#                 'text' : quant_text,\n",
    "#                 'other' : \"Empty\"\n",
    "#             }, ignore_index=True)\n",
    "            \n",
    "            output_list.append([file_name, annot_set_index, tags['QUANT'], sentence[start_ind].idx, sentence[end_ind].idx + len(sentence[end_ind]), annot_index, quant_text, \"\"])\n",
    "            annot_set_index += 1\n",
    "            annot_index += 1\n",
    "        \n",
    "        prev_file = file_name\n",
    "        \n",
    "    result_df = pd.DataFrame(output_list, columns=tsv_columns)\n",
    "    result_df.to_csv(dirname + prev_file + '.tsv', sep=\"\\t\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "indoor-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_list = get_units()\n",
    "\n",
    "train_text_dataframe = raw_text_to_df(train_raw_files)\n",
    "train_text_dataframe.to_csv(\"./CSV/train_text_dataframe.csv\")\n",
    "\n",
    "each_file_df = []\n",
    "for tsv_file in train_tsv_files:\n",
    "    each_file_df.append(pd.read_csv(tsv_file, sep=\"\\t\", header=0))\n",
    "\n",
    "train_tsv_dataframe = pd.concat(each_file_df)\n",
    "train_tsv_dataframe.to_csv(\"./CSV/train_tsv_dataframe.csv\")\n",
    "\n",
    "test_text_dataframe = raw_text_to_df(test_raw_files)\n",
    "test_text_dataframe.to_csv(\"./CSV/test_text_dataframe.csv\")\n",
    "\n",
    "each_file_test = []\n",
    "for tsv_file in test_tsv_files:\n",
    "    each_file_test.append(pd.read_csv(tsv_file, sep=\"\\t\", header=0))\n",
    "\n",
    "test_tsv_dataframe = pd.concat(each_file_test)\n",
    "test_tsv_dataframe.to_csv(\"./CSV/test_tsv_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "robust-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for _, row in train_text_dataframe.iterrows() :\n",
    "    features = features_sentence(row['sentence'], row['entities'], row['np'])\n",
    "    X_train.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hungry-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_text_labels(train_text_dataframe, train_tsv_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tight-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for _, row in test_text_dataframe.iterrows() :\n",
    "    features = features_sentence(row['sentence'], row['entities'], row['np'])\n",
    "    X_test.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hydraulic-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = get_text_labels(test_text_dataframe, test_tsv_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aerial-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train + X_test\n",
    "y_train = y_train + y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "liquid-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "chinese-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_text_dataframe = raw_text_to_df(eval_raw_files)\n",
    "X_eval = []\n",
    "for _, row in eval_text_dataframe.iterrows() :\n",
    "    features = features_sentence(row['sentence'], row['entities'], row['np'])\n",
    "    X_eval.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "scenic-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"results/S0019103512004009-4007.tsv\",sep='\\t')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "boxed-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for i, text_row in test_text_dataframe.iterrows():\n",
    "#         print(type(text_row['sentence'][3].doc))\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "subtle-murder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "published-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "nutritional-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_eval)\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "\n",
    "# print(metrics.flat_classification_report(\n",
    "#     y_test, y_pred, labels=sorted_labels, digits=3\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "narrow-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_to_tsv(eval_text_dataframe, y_pred, 'results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adjustable-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 14.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f553374f4d0>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f553374f750>},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['QUANT']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.5), \n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fluid-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_eval)\n",
    "# print(metrics.flat_classification_report(\n",
    "#     y_test, y_pred, labels=sorted_labels, digits=3\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "strategic-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_to_tsv(eval_text_dataframe, y_pred, 'results_opt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-astronomy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
